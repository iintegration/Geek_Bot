{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Hackathons\\Hack_26_04_2024\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    \n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    NewsSyntaxParser,\n",
    "   \n",
    "    PER,\n",
    "    Doc\n",
    ")\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "from typing import List, Union\n",
    "import pickle\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, model_object = \"\", model_positive = \"\", model_relevant =\"\"):\n",
    "\n",
    "\n",
    "        self.segmenter = Segmenter()\n",
    "        self.morph_vocab = MorphVocab()\n",
    "        self.emb = NewsEmbedding()\n",
    "        self.morph_tagger = NewsMorphTagger(self.emb)\n",
    "        self.syntax_parser = NewsSyntaxParser(self.emb)\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/sbert_large_mt_nlu_ru\", cache_dir = \"model_cache\")\n",
    "        self.model = AutoModel.from_pretrained(\"ai-forever/sbert_large_mt_nlu_ru\", cache_dir = \"model_cache\")\n",
    "        \n",
    "        with open(model_object, \"rb\") as f:\n",
    "            self.knn_object = pickle.load(f)\n",
    "\n",
    "        with open(model_positive, \"rb\") as f:\n",
    "            self.knn_positive = pickle.load(f)\n",
    "\n",
    "        with open(model_relevant, \"rb\") as f:\n",
    "            self.knn_relevant = pickle.load(f)\n",
    "\n",
    "    def __natasha_lemmant(self, input_str):\n",
    "\n",
    "        doc = Doc(input_str)\n",
    "        doc.segment(self.segmenter)\n",
    "        doc.tag_morph(self.morph_tagger)\n",
    "        doc.parse_syntax(self.syntax_parser)\n",
    "        for token in doc.tokens:\n",
    "            token.lemmatize(self.morph_vocab)\n",
    "\n",
    "        result = ' '.join([_.lemma for _ in doc.tokens])\n",
    "        return result\n",
    "\n",
    "\n",
    "\n",
    "    def __clear_string(self, s, stop_words): # Функция для очистки\n",
    "        # print(re.sub(r'[^а-яА-ЯёЁa-zA-Z]', ' ', str(s).lower()).split())\n",
    "        s = ' '.join([val for val in re.sub(r'[^а-яА-ЯёЁa-zA-Z]', ' ', str(s).lower()).split() if not val in stop_words])\n",
    "        # s = ' '.join([val for val in re.sub(r'[^а-яА-ЯёЁ]', ' ', str(s).lower()).split() if not val in stop_words])\n",
    "        return s\n",
    "\n",
    "    def __preprocessing(self, answer):\n",
    "        stop_words = list(stopwords.words('russian'))\n",
    "        \n",
    "        text_list = []\n",
    "\n",
    "        for i in range(len(answer)):\n",
    "            txt = answer[i]['question_2'] + \" \" + answer[i]['question_3'] + \" \" + answer[i]['question_4'] + \" \" + answer[i]['question_5']\n",
    "            txt = self.__clear_string(txt, stop_words)\n",
    "            txt = self.__natasha_lemmant(txt)\n",
    "            text_list.append(txt)\n",
    "\n",
    "        return text_list\n",
    "\n",
    "    def __mean_pooling(self, model_output, attention_mask):\n",
    "        token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "        return sum_embeddings / sum_mask\n",
    "\n",
    "    def __get_embedding(self, text_list):\n",
    "        # print(text_list)\n",
    "\n",
    "        encoded_input = self.tokenizer(text_list, padding=True, truncation=True, max_length=24, return_tensors='pt')\n",
    "        with torch.no_grad():\n",
    "            #Compute token embeddings\n",
    "            model_output = self.model(**encoded_input)\n",
    "\n",
    "        #Perform pooling. In this case, mean pooling\n",
    "        # print(encoded_input['attention_mask'])\n",
    "        # print(model_output)\n",
    "        embeddings = self.__mean_pooling(model_output, encoded_input['attention_mask']).cpu().numpy()\n",
    "\n",
    "        return embeddings\n",
    "\n",
    "    def predict(self, answers: list) -> List[int]:\n",
    "        \n",
    "        # Очищаем текст\n",
    "        answers = self.__preprocessing(answers)\n",
    "\n",
    "        embeddings = self.__get_embedding(answers)\n",
    "        \n",
    "        object_predict = self.knn_object.predict(embeddings)\n",
    "        positive_predict = self.knn_positive.predict(embeddings)\n",
    "        relevant_predict = self.knn_relevant.predict(embeddings)\n",
    "\n",
    "        return {\"object\": object_predict, \"positive\": positive_predict, \"relevant\": relevant_predict}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>is_relevant</th>\n",
       "      <th>object</th>\n",
       "      <th>is_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   key  is_relevant  object  is_positive\n",
       "0    1            0       0            0\n",
       "1    2            0       0            0\n",
       "2    3            0       0            0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame({\"key\":[1, 2, 3], \"is_relevant\": [0, 0, 0], \"object\":[0, 0, 0], \"is_positive\": [0, 0, 0]})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>is_relevant</th>\n",
       "      <th>object</th>\n",
       "      <th>is_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   key  is_relevant  object  is_positive\n",
       "0    1            0       0            1\n",
       "1    2            0       0            2\n",
       "2    3            0       0            3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"is_positive\"] = pd.Series([1, 2, 3])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'key': 1, 'is_relevant': 0, 'object': 0, 'is_positive': 1},\n",
       " {'key': 2, 'is_relevant': 0, 'object': 0, 'is_positive': 2},\n",
       " {'key': 3, 'is_relevant': 0, 'object': 0, 'is_positive': 3}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = json.loads(data.to_json(orient='records'))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка тестового датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv(\"\")\n",
    "\n",
    "data_json = json.loads(data_test.to_json(orient='records'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Hackathons\\Hack_26_04_2024\\.venv\\lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator KNeighborsClassifier from version 1.2.2 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "object_cats = Model(\n",
    "    model_object = \"model_knn\\\\best_model_object.pkl\", \n",
    "    model_positive = \"model_knn\\\\best_model_positive.pkl\", \n",
    "    model_relevant =\"model_knn\\\\best_model_relevant.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2], dtype=int64), array([1], dtype=int64), array([1], dtype=int64))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_cats.predict([{\"question_1\":\"Новейшие тенденции в IT\",\"question_2\":\"Дискуссия о будущем облачных вычислений и их влиянии на ИТ-индустрию была очень проницательной.\",\"question_3\":\"Нет.\",\"question_4\":\"Включить больше кейс-стади от компаний, успешно интегрировавших облачные решения.\",\"question_5\":\"Стратегии миграции предприятий в облако.\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2], dtype=int64), array([1], dtype=int64), array([1], dtype=int64))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_cats.predict([{\"question_1\":\"Новейшие тенденции в IT\",\"question_2\":\"Дискуссия о будущем облачных вычислений и их влиянии на ИТ-индустрию была очень проницательной.\",\"question_3\":\"Нет.\",\"question_4\":\"Включить больше кейс-стади от компаний, успешно интегрировавших облачные решения.\",\"question_5\":\"Стратегии миграции предприятий в облако.\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {\"analysis_result\": [\n",
    "    {\n",
    "      \"user_id\": 1229352473,\n",
    "      \"answers\": {\n",
    "        \"1\": \"Разработка на Next JS\",\n",
    "        \"2\": \"Разнообразие информации и подробное описание как работать с технологиями\",\n",
    "        \"3\": \"Пока не было\",\n",
    "        \"4\": \"Хотелось бы увидеть более удобный интерфейс для взаимодействия между сервисом и пользователем\",\n",
    "        \"5\": \"Backend разработка на Node JS\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"user_id\": 1321034543,\n",
    "      \"answers\": {\n",
    "        \"1\": \"Победители Цифрового прорыва\",\n",
    "        \"2\": \"Больше всего мне понравились сказочные истории, про мечтателей, которые захотели выиграть хакатон когда их фронт отвалился спать+работать\",\n",
    "        \"3\": \"Максимально затруднительно работать, когда фронт лежит\",\n",
    "        \"4\": \"Я считаю, что нам надо улучшить фронтендера, пусть затаривается энергосами - его ждет бессонная ночь\",\n",
    "        \"5\": \"Я бы хотел изучить методы пинания фронтэндеров\"\n",
    "      }\n",
    "    }\n",
    "  ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'1': 'Разработка на Next JS',\n",
       "  '2': 'Разнообразие информации и подробное описание как работать с технологиями',\n",
       "  '3': 'Пока не было',\n",
       "  '4': 'Хотелось бы увидеть более удобный интерфейс для взаимодействия между сервисом и пользователем',\n",
       "  '5': 'Backend разработка на Node JS'},\n",
       " {'1': 'Победители Цифрового прорыва',\n",
       "  '2': 'Больше всего мне понравились сказочные истории, про мечтателей, которые захотели выиграть хакатон когда их фронт отвалился спать+работать',\n",
       "  '3': 'Максимально затруднительно работать, когда фронт лежит',\n",
       "  '4': 'Я считаю, что нам надо улучшить фронтендера, пусть затаривается энергосами - его ждет бессонная ночь',\n",
       "  '5': 'Я бы хотел изучить методы пинания фронтэндеров'}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[val['answers'] for val in test[\"analysis_result\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = {'1': 0.6963162660598755, '2': 0.3210538327693939, '0': 0.3826298415660858, }\n",
    "max(test, key=test.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
